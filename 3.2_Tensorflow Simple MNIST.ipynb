{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple MNIST Handwritten digits detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-97e2561fb3c1>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "batch_xs, batch_ys = mnist.train.next_batch(1)\n",
    "img = batch_xs[0].reshape([28, 28])\n",
    "label = batch_ys[0]\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/mnist_two_layers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 784 = 28x28 images\n",
    "# None: We don't know how many items will be in this dimension\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name=\"input\")\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# Weights and bias\n",
    "# variables: we need to change this values when the model learns\n",
    "fc1_W = tf.Variable(tf.truncated_normal([784, 10], stddev=0.1))\n",
    "fc1_b = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "fc1 = tf.nn.relu(tf.matmul(x, fc1_W) + fc1_b)\n",
    "\n",
    "fc2_W = tf.Variable(tf.truncated_normal([10, 10], stddev=0.1))\n",
    "fc2_b = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "\n",
    "# define our model\n",
    "y = tf.nn.softmax(tf.matmul(fc1, fc2_W) + fc2_b, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-56daf663dc01>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loss\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Optimization\n",
    "![title](images/optimization.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss optimization\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=0.5) \\\n",
    "    .minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate\n",
    "![title](images/learning_rate.png)\n",
    "![title](images/learning_rate_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is correct\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "\n",
    "# How accurate is it\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, training accuracy 10.000%\n",
      "Step 200, training accuracy 84.000%\n",
      "Step 400, training accuracy 82.000%\n",
      "Step 600, training accuracy 80.000%\n",
      "Step 800, training accuracy 92.000%\n",
      "Step 1000, training accuracy 96.000%\n",
      "Step 1200, training accuracy 94.000%\n",
      "Step 1400, training accuracy 98.000%\n",
      "Step 1600, training accuracy 100.000%\n",
      "Step 1800, training accuracy 88.000%\n",
      "Step 2000, training accuracy 96.000%\n",
      "Step 2200, training accuracy 100.000%\n",
      "Step 2400, training accuracy 90.000%\n",
      "Step 2600, training accuracy 94.000%\n",
      "Step 2800, training accuracy 92.000%\n"
     ]
    }
   ],
   "source": [
    "# Init all variables\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Train the model\n",
    "num_steps = 3000\n",
    "batch_size = 32\n",
    "display_every = 200\n",
    "\n",
    "for i in range(num_steps):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "    if i % display_every == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x: batch_xs, y_: batch_ys\n",
    "        })\n",
    "        print(\"Step {0}, training accuracy {1:.3f}%\"\n",
    "              .format(i, train_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate results of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 91.360%\n"
     ]
    }
   ],
   "source": [
    "# accuracy on test data\n",
    "validation_accuracy = accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels\n",
    "})\n",
    "\n",
    "print(\"Validation Accuracy: {0:.3f}%\".format(validation_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n",
      "INFO:tensorflow:Converted 4 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "\n",
    "graph_path = \"models/tensorflow-simple_mnist.pb\"\n",
    "graph_path_text = \"models/tensorflow-simple_mnist.pb.txt\"\n",
    "\n",
    "minimal_graph = convert_variables_to_constants(sess, sess.graph_def, [\"output\"])\n",
    "tf.train.write_graph(minimal_graph, '.', graph_path, as_text=False)\n",
    "tf.train.write_graph(minimal_graph, '.', graph_path_text, as_text=True)\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict an image from saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import/input\n",
      "import/Variable\n",
      "import/Variable/read\n",
      "import/Variable_1\n",
      "import/Variable_1/read\n",
      "import/MatMul\n",
      "import/add\n",
      "import/Relu\n",
      "import/Variable_2\n",
      "import/Variable_2/read\n",
      "import/Variable_3\n",
      "import/Variable_3/read\n",
      "import/MatMul_1\n",
      "import/add_1\n",
      "import/output\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "graph_def = tf.GraphDef()\n",
    "\n",
    "with open(graph_path, \"rb\") as f:\n",
    "  graph_def.ParseFromString(f.read())\n",
    "with graph.as_default():\n",
    "  tf.import_graph_def(graph_def)\n",
    "\n",
    "for op in graph.get_operations():\n",
    "    print(str(op.name))\n",
    "\n",
    "input_layer = \"input\"\n",
    "output_layer = \"output\"\n",
    "\n",
    "input_operation = graph.get_operation_by_name(\"import/\" + input_layer)\n",
    "output_operation = graph.get_operation_by_name(\"import/\"+ output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22892909128>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = mnist.test.images[0]\n",
    "print(x.shape)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# display image\n",
    "img = x.reshape([28, 28])\n",
    "print(img.shape)\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0191884e-10 1.3174799e-17 3.7008646e-11 7.0597736e-07 6.4864994e-16\n",
      " 7.2862286e-11 1.6200912e-22 9.9999928e-01 6.1715793e-12 2.7162086e-10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "  results = session.run(output_operation.outputs[0], {\n",
    "      input_operation.outputs[0]: x\n",
    "  })\n",
    "\n",
    "predictions = results[0]\n",
    "print(predictions)\n",
    "np.argmax(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
