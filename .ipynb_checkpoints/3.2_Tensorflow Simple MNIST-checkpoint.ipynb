{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple MNIST Handwritten digits detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "batch_xs, batch_ys = mnist.train.next_batch(1)\n",
    "img = batch_xs[0].reshape([28, 28])\n",
    "label = batch_ys[0]\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/mnist_two_layers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 784 = 28x28 images\n",
    "# None: We don't know how many items will be in this dimension\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# Weights and bias\n",
    "# variables: we need to change this values when the model learns\n",
    "fc1_W = tf.Variable(tf.truncated_normal([784, 10], stddev=0.1))\n",
    "fc1_b = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "fc1 = tf.nn.relu(tf.matmul(x, fc1_W) + fc1_b)\n",
    "\n",
    "fc2_W = tf.Variable(tf.truncated_normal([10, 10], stddev=0.1))\n",
    "fc2_b = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "\n",
    "# define our model\n",
    "y = tf.nn.softmax(tf.matmul(fc1, fc2_W) + fc2_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss optimization\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=0.5) \\\n",
    "    .minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is correct\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "\n",
    "# How accurate is it\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, training accuracy 26.000%\n",
      "Step 200, training accuracy 70.000%\n",
      "Step 400, training accuracy 84.000%\n",
      "Step 600, training accuracy 82.000%\n",
      "Step 800, training accuracy 86.000%\n",
      "Step 1000, training accuracy 86.000%\n",
      "Step 1200, training accuracy 82.000%\n",
      "Step 1400, training accuracy 82.000%\n",
      "Step 1600, training accuracy 92.000%\n",
      "Step 1800, training accuracy 94.000%\n",
      "Step 2000, training accuracy 88.000%\n",
      "Step 2200, training accuracy 94.000%\n",
      "Step 2400, training accuracy 96.000%\n",
      "Step 2600, training accuracy 92.000%\n",
      "Step 2800, training accuracy 96.000%\n"
     ]
    }
   ],
   "source": [
    "# Init all variables\n",
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Trian the model\n",
    "num_steps = 3000\n",
    "batch_size = 50\n",
    "display_every = 200\n",
    "\n",
    "for i in range(num_steps):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "    if i % display_every == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x: batch_xs, y_: batch_ys\n",
    "        })\n",
    "        print(\"Step {0}, training accuracy {1:.3f}%\"\n",
    "              .format(i, train_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate results of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.918%\n"
     ]
    }
   ],
   "source": [
    "# accuracy on test data\n",
    "validation_accuracy = accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels\n",
    "})\n",
    "\n",
    "print(\"Validation Accuracy: {0:.3f}%\".format(validation_accuracy))\n",
    "\n",
    "sess.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
